# Example Judge Panel Configuration for Rubric Kit
# ===================================================
# This file demonstrates how to configure a multi-judge panel for more
# reliable and robust evaluation results.
#
# Rubric Kit uses LiteLLM to support 100+ LLM providers with a unified interface.
# API keys are configured via environment variables (never in config files).
#
# Full documentation: https://docs.litellm.ai/docs/providers
#
# Model Name Formats (LiteLLM):
# - OpenAI: "gpt-4", "gpt-4o"
# - Google AI Studio: "gemini/gemini-2.5-flash" (uses GEMINI_API_KEY)
# - Google Vertex AI: "vertex_ai/gemini-2.5-flash" (uses gcloud auth)
# - IBM WatsonX: "watsonx/meta-llama/llama-3-8b-instruct"
# - Anthropic: "claude-3-5-sonnet-20241022"
# - Ollama (local): "ollama/llama3", "ollama/mistral"
#
# Environment Variables (set before running):
# - OPENAI_API_KEY: For OpenAI models
# - GEMINI_API_KEY: For Google AI Studio models (gemini/...)
# - GOOGLE_APPLICATION_CREDENTIALS or `gcloud auth`: For Vertex AI (vertex_ai/...)
# - WATSONX_APIKEY + WATSONX_PROJECT_ID: For IBM WatsonX
# - ANTHROPIC_API_KEY: For Anthropic Claude

judge_panel:
  # List of judges (LLM models) that will evaluate each criterion
  # Each judge evaluates independently, then results are combined via consensus
  judges:
    # OpenAI judge - uses OPENAI_API_KEY from environment
    - name: openai-gpt4
      model: gpt-4o

    # Google AI Studio judge - uses GEMINI_API_KEY from environment
    # Simpler setup than Vertex AI, just need an API key from https://aistudio.google.com
    - name: gemini-judge
      model: gemini/gemini-2.5-flash
      temperature: 0.3

    # Local Ollama judge - no API key needed, runs locally
    - name: ollama-local
      model: ollama/llama3

    # Example: Google Vertex AI judge (alternative to AI Studio)
    # Uses gcloud auth or GOOGLE_APPLICATION_CREDENTIALS
    # - name: vertex-judge
    #   model: vertex_ai/gemini-2.5-flash

    # Example: IBM WatsonX judge
    # Requires: WATSONX_APIKEY and WATSONX_PROJECT_ID environment variables
    # - name: watsonx-judge
    #   model: watsonx/meta-llama/llama-3-8b-instruct

    # Example: Anthropic Claude judge
    # Requires: ANTHROPIC_API_KEY environment variable
    # - name: claude-judge
    #   model: claude-3-5-sonnet-20241022

    # Example: OpenAI-compatible endpoint (vLLM, LocalAI, etc.)
    # - name: custom-endpoint
    #   model: mistral-7b  # Model name expected by your endpoint
    #   base_url: http://your-server:8000/v1

    # Example: Judge with custom inference parameters
    # - name: creative-judge
    #   model: gpt-4
    #   temperature: 0.8
    #   top_p: 0.9
    #   frequency_penalty: 0.1
    #   presence_penalty: 0.2

  # Execution configuration: How judges are called
  execution:
    # Mode options:
    # - "sequential": Call judges one by one (safest for rate limits, default)
    # - "parallel": Call all judges simultaneously (fastest, may hit rate limits)
    # - "batched": Call judges in batches (balanced approach)
    mode: batched
    
    # Batch size (only used when mode is "batched")
    # Determines how many judges are called simultaneously in each batch
    batch_size: 3
    
    # Timeout in seconds for each individual judge call
    # If a judge takes longer than this, it will be considered failed
    timeout: 240
  
  # Consensus configuration: How judge votes are combined
  consensus:
    # Mode options:
    # - "quorum": Specific number of judges must agree (threshold required)
    # - "majority": More than 50% must agree (threshold auto-calculated)
    # - "unanimous": All judges must agree (threshold = number of judges)
    mode: quorum
    
    # Threshold: Minimum number of judges that must agree on the same result
    # Required for "quorum" mode, auto-calculated for "majority" and "unanimous"
    # In this example with 3 judges and threshold 2: at least 2 must agree
    threshold: 2
    
    # What to do when consensus is not reached:
    # - "fail": Use conservative approach (minimum score or fail) - DEFAULT
    # - "median": Use median of all judge scores (for score-based criteria)
    # - "most_common": Use most frequent result (ties broken conservatively)
    on_no_consensus: fail
